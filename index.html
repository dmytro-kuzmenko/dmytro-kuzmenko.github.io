<!doctype html>
<html>

<div class="page-background"></div>

<head>

<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="chrome=1">
<title>Dmytro Kuzmenko's webpage</title>

<link rel="stylesheet" href="stylesheets/styles.css">
<link rel="stylesheet" href="stylesheets/extra_min_styles.css">

<meta name="viewport" content="width=device-width">

    <!-- Icons -->
<link rel="stylesheet" href="stylesheets/css/academicons.css"/>
<link rel="stylesheet" href="stylesheets/css/font-awesome.css"/>
<link rel="stylesheet" href="stylesheets/css/academicons.min.css"/>
<link rel="stylesheet" href="stylesheets/style-svg.html">

<!-- Meta Pixel Code -->
<script>
!function(f,b,e,v,n,t,s)
{if(f.fbq)return;n=f.fbq=function(){n.callMethod?
n.callMethod.apply(n,arguments):n.queue.push(arguments)};
if(!f._fbq)f._fbq=n;n.push=n;n.loaded=!0;n.version='2.0';
n.queue=[];t=b.createElement(e);t.async=!0;
t.src=v;s=b.getElementsByTagName(e)[0];
s.parentNode.insertBefore(t,s)}(window, document,'script',
'https://connect.facebook.net/en_US/fbevents.js');
fbq('init', '263777962599205');
fbq('track', 'PageView');
</script>
<noscript><img height="1" width="1" style="display:none"
src="https://www.facebook.com/tr?id=263777962599205&ev=PageView&noscript=1"
/></noscript>
<!-- End Meta Pixel Code -->

</head>

<body background="./background.jpeg" data-new-gr-c-s-check-loaded="8.876.0" data-gr-ext-installed=""><div class="wrapper">

    <!-- HEADER -->
    <header>
        <h1 align="center">Dmytro Kuzmenko</h1>

        <!-- Picture + Links + News -->
        <div style="margin-bottom: 10px" align="center">

            <!-- Portrait -->
            <!-- <img src="images/portrait.JPG" alt="Portrait" WIDTH=160 style="margin-bottom: 8px;border-radius: 10px;"> -->
            <img src="./files/M1.jpg" alt="Portrait" class="portrait">

            <!-- Email -->
            <!-- <div style="margin-bottom: 6px;"><img src="./files/email.png" width="175"></div> -->
            <div style="margin-bottom: 15px;"><a href = "mailto: dmytro.o.kuzmenko@gmail.com">dmytro.o.kuzmenko@gmail.com</a>

            <br>

            <!-- CV -->
<!--             <a href="./files/CV-DmytroKuzmenko.pdf" style="margin-right:14px;">
                <i class="ai ai-cv" style="font-size: 32px;"></i>
            </a> -->

            <!-- LinkedIn -->
            <a href="https://www.linkedin.com/in/dmytrookuzmenko/" style="margin-right:14px;">
                <i class="fa fa-linkedin" style="font-size:32px;"></i>
            </a>

            <!-- Git -->
            <a href="https://github.com/righteousronin" style="margin-right:14px;">
                <i class="fa fa-github" style="font-size:32px;"></i>
                <!-- color: #A7A499" -->
            </a>

            <!-- Medium -->
            <a href="https://righteous-ronin.medium.com" style="margin-right:14px;">
                <i class="fa fa-medium" style="font-size:32px;"></i>
            </a>

            <!-- Twitter -->
            <a href="https://twitter.com/kuzmenko_dmytro" style="margin-right:14px;">
                <i class="fa fa-twitter" style="font-size:32px;"></i>
            </a>
            <br>
            <br>
        </div>

    </header>

    <section>

    <h1>Greetings!</h1>
    <p>I am a Data Science Tech Lead, ML researcher, mentor, lecturer, MSc in Applied Mathematics at NaUKMA.</p>

	<p>My research directions combine ML, CV, and RL in Healthcare and Assistive Technology. I have devised multiple ML pipelines that are still being used in production. The research focus is on Adversarial Robustness in DL models. Guided many mentees and read a multitude of lectures at different institutions.</p>

    <p>Keen on making fresh paper reviews and playing shogi. Striving to expand AI and empower research potential in Ukraine.</p>

    <p>
    	Research areas of interest: 
    	<br>
		➣ Adversarial attacks and adversarial robustness
		<br>
		➣ Semi-supervised learning and transformers in computer vision
		<br>
		➣ Reinforcement learning (single- and multi-agent setups)
		<br>
		<br>
		For collaboration suggestions and other inquiries reach out to <a href = "mailto: dmytro.o.kuzmenko@gmail.com">dmytro.o.kuzmenko@gmail.com.</a>
	</p>

<!--     <p>
    	Book a mentoring session via <a href="https://www.prjctrmentor.com/mentor/dmytro-kuzmenko" target="_blank" rel="noopener noreferrer">Projector Mentorship Platform.</a>
    </p> -->
    
    <h3>Recent News</h3>
    <ul>
        <li>2023-01: Began teaching a master's course on <a href="https://youtube.com/playlist?list=PL-XXuLw8QpKHItstwKJsYfwBhlhJrxY_t" target="_blank" rel="noopener noreferrer">"Reinforcement Learning"</a> at NaUKMA. </li>
    	<li>2022-12: Got acknowledged as a research assistant and a part of <a href="https://iatsl.org/people/dkuzmenko.html" target="_blank" rel="noopener noreferrer">IATSL </a>lab!</li>
    	<li>2022-11: Joined <a href="https://litslink.com/" target="_blank" rel="noopener noreferrer"> LITSLINK</a> as a Data Science tech lead.</li>
    	<li>2022-10: Created a <a href="https://www.youtube.com/@dmytro_o_kuzmenko" target="_blank" rel="noopener noreferrer">YouTube channel </a> with recordings of my events and ML/CV master's courses.</li>
    	<li>2022-10: Joined CSC2431: AI in Medicine w/ UoFT, UCU, and NaUKMA as a course instructor.</li>
    	<li>2022-10: Started off as an Assistant Lecturer at NaUKMA!</li>
    	<li>2022-10: Presented a breakdown of fresh-from-the-oven <a href="https://www.aihouse.club/paperclubs/13" target="_blank" rel="noopener noreferrer">Mega Attention</a> at <a href="https://www.aihouse.club/" target="_blank" rel="noopener noreferrer">AI House Paper Club.</a></li>
    	<li>2022-09: Held a technical talk on the topic of <a href="https://youtu.be/uNcyV99AB9g" target="_blank" rel="noopener noreferrer">Adversarial Attacks and Robustness</a> at Faculty of CS, NaUKMA.</li>
    	<li>2022-09: Introduced concepts of <a href="https://docs.google.com/presentation/d/12cTfHHzbgwyRvmLSvFcO-39ReRw5UdW1ryw7lAB43DU/edit?usp=sharing" target="_blank" rel="noopener noreferrer"> different ML tasks</a> at Faculty of CS, NaUKMA.</li>
    	<li>2022-08: Gave a tech talk on Vision Transformers at <a href="https://data-science-ua.com/" target="_blank" rel="noopener noreferrer">Data Science UA.</a></li>
    	<li>2022-08: Started mentoring at <a href="https://www.womenwhocode.com" target="_blank" rel="noopener noreferrer">WWCode.</a></li>
    	<li>2022-05: Held a lecture on the topic regression in ML, became a Mentor at Projector Institute. <a href="https://prjctr.com/library/video/vstup-do-regresiyi-v-mashinnomu-navchanni" target="_blank" rel="noopener noreferrer">Lecture link.</a></li>
<!--     	<li>2022-04: Enrolled as ML Researcher at <a href="https://iatsl.org/" target="_blank" rel="noopener noreferrer">IATSL, University of Toronto.</a></li> -->
<!--         <li>2022-03: Started an AI-related <a href="https://t.me/aicoven" target="_blank" rel="noopener noreferrer">Telegram channel</a> and <a href="https://righteous-ronin.medium.com" target="_blank" rel="noopener noreferrer">a Medium blog.</a></li> -->
<!--         <li>2021-12: <a href="https://gdsc.community.dev/events/details/developer-student-clubs-kyiv-school-of-economics-presents-machine-learning-vs-software-engineering-overview-of-ai-foundations-and-application-areas/" target="_blank" rel="noopener noreferrer">Held an ML/SWE-centered lecture</a> for students of Kyiv School of Economics.</li> -->
<!--         <li>2021-09: <a href="https://youtu.be/M7cR-Sd4XU0" target="_blank" rel="noopener noreferrer">Pitched</a> a virtual try-on and wardrobe recommender system at WILD WILD HACK 2021.</li> -->
        <!-- <li>2021-09: Started Masters in Applied Mathematics at NaUKMA.</li>
        <li>2021-06: Got Bachelors in SWE at NaUKMA.</li>
        <li>2021-05: Architectured an <a href="http://ekmair.ukma.edu.ua/bitstream/handle/123456789/22455/Kuzmenko_Bakalavrska_robota.pdf?sequence=1&isAllowed=y" target="_blank" rel="noopener noreferrer">open-data system</a> for the State Register of Court Decisions for YouControl.</li> -->
    </ul>

    <!-- Paper review table  -->
    <h3> Highlights </h3>
    <table style="margin-top:-12px;">

    	<!-- IATSL addition -->
        <tbody><tr style="border-bottom:1px solid #e5e5e5;">
            <!-- IMAGE -->
            <td>
                <img class="workPicture" src="files/iatsl.png" alt="iatsl profile">
            </td>
            <!-- TITLE AND INFO -->
            <td>
                <br>
                <div id="indexWorkText">
                    <!-- Title + Link -->
                    <b><a href="https://iatsl.org/people/dkuzmenko.html">Recognized as a research assistant and part of the team at IATSL </a></b>
                    <br>
                    <i>1 Dec 2022</i>
                </div>
                <br>
                <!-- One sentence description -->
                <div id="indexWorkText">
                	<a href="https://iatsl.org/team.htm">IATSL</a> is a multi-disciplinary group of researchers that develops adaptive and intelligent technologies to enable users to participate fully in their daily activities.
                </div>
                <br>
                <br>
            </td>
        </tr>     
        </tbody>

        <!-- YT addition -->
        <tbody><tr style="border-bottom:1px solid #e5e5e5;">
            <!-- IMAGE -->
            <td>
                <img class="workPicture" src="files/yt.png" alt="yt channel">
            </td>
            <!-- TITLE AND INFO -->
            <td>
                <br>
                <div id="indexWorkText">
                    <!-- Title + Link -->
                    <b><a href="https://www.youtube.com/@dmytro_o_kuzmenko/videos">Authored a YT channel with Machine Learning and Computer Vision courses at NaUKMA </a></b>
                    <br>
                    <i>19 Oct 2022</i>
                </div>
                <br>
                <!-- One sentence description -->
                <div id="indexWorkText">
                	Recordings of practical assignments and lectures from <a href="https://youtube.com/playlist?list=PL-XXuLw8QpKF3RGHxAeVf2iQfi2CeWSAb">Computer Vision</a> and <a href="https://youtube.com/playlist?list=PL-XXuLw8QpKHrGzxs0agw8XuxtjmcdKmz">Machine Learning</a> Master's courses at NaUKMA.
                </div>
                <br>
                <br>
            </td>
        </tr>     
        </tbody>

    	<!-- AI House Paper club -->
        <tbody><tr style="border-bottom:1px solid #e5e5e5;">
            <!-- IMAGE -->
            <td>
                <img class="workPicture" src="files/aihouse.jpg" alt="aihouse">
            </td>
            <!-- TITLE AND INFO -->
            <td>
                <br>
                <div id="indexWorkText">
                    <!-- Title + Link -->
                    <b><a href="https://www.aihouse.club/paperclubs/13">"Mega: Moving Average Equipped Gated Attention" at AI House Club </a></b>
                    <br>
                    <i>7 Oct 2022</i>
                </div>
                <br>
                <!-- One sentence description -->
                <div id="indexWorkText">
                	A breakdown of Mega attention, a fresh optimized linear-complexity mechanism with exponential moving average to further improve sequence modeling tasks.
                </div>
                <br>
                <br>
            </td>
        </tr>     
        </tbody>

        <!-- CSC2431 -->
        <tbody><tr style="border-bottom:1px solid #e5e5e5;">
            <!-- IMAGE -->
            <td>
                <img class="workPicture" src="files/csc2431.png" alt="csc2431">
            </td>
            <!-- TITLE AND INFO -->
            <td>
                <br>
                <div id="indexWorkText">
                    <!-- Title + Link -->
                    <b><a href="https://data-team-uhn.github.io/csc2431/">Enrolled as a course instructor in CSC2431: AI in Medicine </a></b>
                    <br>
                    <i>3 Oct 2022</i>
                </div>
                <br>
                <!-- One sentence description -->
                <div id="indexWorkText">
                	A cooperation course for Ukrainian students from UCU and NaUKMA to work together with senior PhD students from UofT on their theses.  
                </div>
                <br>
                <br>
            </td>
        </tr>     
        </tbody>

    	<!-- DS UA Event -->
        <tbody><tr style="border-bottom:1px solid #e5e5e5;">
            <!-- IMAGE -->
            <td>
                <img class="workPicture" src="files/dsua.jpg" alt="DSUA">
            </td>
            <!-- TITLE AND INFO -->
            <td>
                <br>
                <div id="indexWorkText">
                    <!-- Title + Link -->
                    <b><a href="https://youtu.be/V_OGUb2uKP0">"Evolution of Vision Transformers: from ViT to GC ViT and Next-ViT" at Data Science UA </a></b>
                    <br>
                    <i>9 Aug 2022</i>
                </div>
                <br>
                <!-- One sentence description -->
                <div id="indexWorkText">
                	A technical breakdown of the State-of-the-Art hybrid CNN-Transformer architectures with great inference and performance.
                </div>
                <br>
                <br>
            </td>
        </tr>     
        </tbody>


    	<!-- Event -->
        <tbody><tr style="border-bottom:1px solid #e5e5e5;">
            <!-- IMAGE -->
            <td>
                <img class="workPicture" src="files/lecture.png" alt="Lecture">
            </td>
            <!-- TITLE AND INFO -->
            <td>
                <br>
                <div id="indexWorkText">
                    <!-- Title + Link -->
                    <b><a href="https://prjctr.com/library/video/vstup-do-regresiyi-v-mashinnomu-navchanni">"Intro to Regression in Machine Learning" at Projector Institute </a></b>
                    <br>
                    <i>16 May 2022</i>
                </div>
                <br>
                <!-- One sentence description -->
                <div id="indexWorkText">
                	Held an introductory guest lecture on the basics of regression in ML, showcased a full modelling pipeline.
                </div>
                <br>
                <br>
            </td>
        </tr>     
        </tbody>

        <!-- Review -->
        <tbody><tr style="border-bottom:1px solid #e5e5e5;">
            <!-- IMAGE -->
            <td>
                <img class="workPicture" src="projects/cg.png" alt="CLIP-Gen overview">
            </td>

            <!-- TITLE AND INFO -->
            <td>
                <br>
                <div id="indexWorkText">
                    <!-- Title + Link -->
                    <b><a href="https://righteous-ronin.medium.com/overview-zerogen-efficient-zero-shot-learning-via-dataset-generation-8ebca0c72620">Overview — CLIP-Gen </a></b>
                    <br>
                    <i>9 May 2022</i>
                </div>
                <br>
                <!-- One sentence description -->
                <div id="indexWorkText">
                    The authors propose a self-supervised scheme named CLIP-GEN for general text-to-image generation with the language-image priors extracted with a pre-trained CLIP model.
                </div>
                <br>
                <br>
            </td>
        </tr>     
        </tbody>

        <!-- Review -->
        <tbody><tr style="border-bottom:1px solid #e5e5e5;">
            <!-- IMAGE -->
            <td>
                <img class="workPicture" src="projects/zerogen.png" alt="ZeroGEN overview">
            </td>

            <!-- TITLE AND INFO -->
            <td>
                <br>
                <div id="indexWorkText">
                    <!-- Title + Link -->
                    <b><a href="https://righteous-ronin.medium.com/overview-zerogen-efficient-zero-shot-learning-via-dataset-generation-8ebca0c72620">Overview — ZeroGen, Efficient Zero-shot Learning via Dataset Generation </a></b>
                    <br>
                    <i>29 Apr 2022</i>
                </div>
                <br>
                <!-- One sentence description -->
                <div id="indexWorkText">
                    An interesting take on zero-shot learning was introduced in a paper that was dated Feb 16.
                </div>
                <br>
                <br>
            </td>
        </tr>     
        </tbody>

    	<!-- Review -->
        <tbody><tr style="border-bottom:1px solid #e5e5e5;">
            <!-- IMAGE -->
            <td>
                <img class="workPicture" src="projects/AutoDIME.png" alt="AutoDIME overview">
            </td>

            <!-- TITLE AND INFO -->
            <td>
                <br>
                <div id="indexWorkText">
                    <!-- Title + Link -->
                    <b><a href="https://righteous-ronin.medium.com/overview-autodime-automatic-design-of-interesting-multi-agent-environments-6ee7fd3085">Overview — AutoDIME, Automatic Design of Interesting Multi-Agent Environments </a></b>
                    <br>
                    <i>21 Apr 2022</i>
                </div>
                <br>
                <!-- One sentence description -->
                <div id="indexWorkText">
                    The paper generalises curriculum learning for environment generation to multi-agent environments. Teacher-Student Curriculum Learning is used, where an RL-trained teacher samples environments of one or several student agents and is trained alongside the students.
                </div>
                <br>
                <br>
            </td>
        </tr>     
        
        </tbody>
          
        <!-- Work -->
        <tbody><tr style="border-bottom:1px solid #e5e5e5;">
            <!-- IMAGE -->
            <td>
                <img class="workPicture" src="projects/LiDAR-4D-DS-Net.png" alt="LiDAR overview">
            </td>

            <!-- TITLE AND INFO -->
            <td>
                <br>
                <div id="indexWorkText">
                    <!-- Title + Link -->
                    <b><a href="https://righteous-ronin.medium.com/overview-2022-03-14-lidar-based-4d-panoptic-segmentation-via-dynamic-shifting-network-2e06733a21d7">Overview — LiDAR-based 4D Panoptic Segmentation via Dynamic Shifting Network </a></b>
                    <br>
                    <i>24 Mar 2022</i>
                </div>
                <br>
                <!-- One sentence description -->
                <div id="indexWorkText">
                    Dynamic Shifting Network (DS-Net) is proposed, which serves as an effective panoptic segmentation framework in the point cloud realm.
                </div>
                <br>
                <br>
            </td>
        </tr>     
        
        </tbody>

        <!-- Review 2 -->

        <!-- Work -->
        <tbody><tr style="border-bottom:1px solid #e5e5e5;">
            <!-- IMAGE -->
            <td>
                <img class="workPicture" src="projects/BlockRecurrentTransformer.png" alt="Block-Recurrent Transformer overview">
            </td>

            <!-- TITLE AND INFO -->
            <td>
                <br>
                <div id="indexWorkText">
                    <!-- Title + Link -->
                    <b><a href="https://righteous-ronin.medium.com/block-recurrent-transformer-overview-9a6e25078672"> Overview — Block-Recurrent Transformer </a></b>
                    <br>
                    <i>21 Mar 2022</i>
                </div>
                <br>
                <!-- One sentence description -->
                <div id="indexWorkText">
                    The authors introduce the Block-Recurrent Transformer, which applies a transformer layer in a recurrent fashion along a sequence, and has linear complexity with respect to the sequence length.
                </div>
                <br>
                <br>
            </td>
        </tr>     
        
        </tbody>

        <!-- Review 3 -->

        <!-- Work -->
        <tbody><tr style="border-bottom:1px solid #e5e5e5;">
            <!-- IMAGE -->
            <td>
                <img class="workPicture" src="projects/VideoSwin.png" alt="Video Swin overview">
            </td>

            <!-- TITLE AND INFO -->
            <td>
                <br>
                <div id="indexWorkText">
                    <!-- Title + Link -->
                    <b><a href="https://righteous-ronin.medium.com/video-swin-transformer-overvie-8fcc9b3f4f63"> Overview — Video Swin Transformer </a></b>
                    <br>
                    <i>16 Mar 2022</i>
                </div>
                <br>
                <!-- One sentence description -->
                <div id="indexWorkText">
                    Video Swin Transformer advocates an inductive bias of locality in video Transformers, leading to a better speed-accuracy trade-off compared to previous approaches which compute self-attention globally even with spatial-temporal factorization.
                </div>
                <br>
                <br>
            </td>
        </tr>     
        
        </tbody>

        <!-- Review 4 -->

        <!-- Work -->
        <tbody><tr style="border-bottom:1px solid #e5e5e5;">
            <!-- IMAGE -->
            <td>
                <img class="workPicture" src="projects/LipSound2.png" alt="LipSound2 overview">
            </td>

            <!-- TITLE AND INFO -->
            <td>
                <br>
                <div id="indexWorkText">
                    <!-- Title + Link -->
                    <b><a href="https://righteous-ronin.medium.com/overview-lipsound2-self-supervised-pre-training-for-lip-to-speech-reconstruction-and-lip-reading-6a50ec3d2818"> Overview — LipSound2: Self-Supervised Pre-Training for Lip-to-Speech Reconstruction and Lip Reading </a></b>
                    <br>
                    <i>13 Mar 2022</i>
                </div>
                <br>
                <!-- One sentence description -->
                <div id="indexWorkText">
                    The authors propose LipSound2 which consists of an encoder-decoder architecture and location-aware attention mechanism to map face image sequences to mel-scale spectrograms directly without requiring any human annotations.
                </div>
                <br>
                <br>
            </td>
        </tr>     
        
        </tbody></table>

    <!-- </table> -->
    </section> 

<footer>
    <br>
    <p style="line-height: 1.2;" align="center"><small>Website is based</a> on <a href="https://github.com/orderedlist/minimal">minimal</a> <br>
        &copy; Dmytro Kuzmenko 2023 </small></p>
</footer>
</div>
<script src="javascripts/scale.fix.js"></script>
</body>	
</html>
